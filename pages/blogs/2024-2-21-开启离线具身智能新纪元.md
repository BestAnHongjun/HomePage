layout: post
title:  LMDeploy-Jetson：在NVIDIA Jetson平台离线部署大模型，开启离线具身智能新纪元
date:   2024-2-21-20-36-00
categories: Jetson
id: 9
------

自ChatGPT-3.5问世以来，大模型(LLM)成为当下学术界和工业界共同研究的热点。大模型可以与智能机器人相结合，使机器人具备理解人类模糊意图及自主任务规划的能力，即“具身智能”。但是，由于大模型在推理时会占用大量计算资源，使其在相当长的一段时间内只能在高性能服务器上运行，如果要应用于智能机器人，通常会采用云服务的形式，不妨归纳为“在线具身智能”范式：智能机器人为端侧，大模型部署于云端服务器，机器人向云端服务器发送请求并得到回应，然后执行相应任务。比如上周作者与百度飞桨、宇树科技合作的Demo”基于文心一言大模型的机器狗“采用的就是这种范式：[[传送门]](/projects.php?url=pages%2Fprojects%2F2024-2-13-基于文心一言大模型的机器狗.md)。

但这种范式的局限性也是非常明显的，即“智能”能力严重依赖互联网。如果网络环境不佳，容易导致请求响应慢，表现为机器人需要很长的思考时间才能执行下一步动作，使得该范式不适合应用于对实时性要求较高的任务。如果应用场景不存在网络环境，那基本与“具身智能”无缘了，比如水下自主机器人(AUV)等。因此，我们有必要探索“离线具身智能”的可能性：无需互联网，大模型直接在智能机器人的计算设备上运行。

作者年初参加了[上海人工智能实验室](https://www.shlab.org.cn/)组织的[书生·浦语大模型实战营](https://github.com/InternLM/tutorial/)，学习了大模型应用相关的技术栈。在学习的过程中接触到了他们开发的大模型轻量化部署工具[LMDeploy](https://github.com/InternLM/lmdeploy/)，发现该工具可以将大模型通过W4A16方式对模型进行量化，从而压缩模型在推理时的显存占用，20B参数量的模型推理时显存占用仅有不到16G。作者之前做过一些模型部署的工作，与NVIDIA Jetson系列板卡接触较多，16G这个数字数字一下子就引起来我的注意：这不NX板卡的内存大小么！既然在服务器上能跑，那有没有可能在Jetson板卡上也能跑？为此作者特意询问了一下浦语小助手（实战营的老师）LMDeploy有没有尝试过在Jetson上部署，然鹅他们并没有这方面的计划，于是作者准备自己尝试一下。

不试不知道，一试吓一跳。昨天下午终于得空，心血来潮开始倒腾，凭借多年的踩坑经验，经历了无数error，成功将LMDeploy移植到了Jetson板卡。废话不多说，直接上结果：

* ✅：已验证可运行
* ❌：已验证不可运行
* ⭕️：待验证

|Models|InternLM-7B|InternLM-20B|InternLM2-1.8B|InternLM2-7B|InternLM2-20B|
|:-:|:-:|:-:|:-:|:-:|:-:|
|Orin NX(16G)<br>Jetpack 5.1|✅<br>Mem:8.6G/16G<br>*7.39 token/s*|✅<br>Mem:14.7G/16G<br>*3.08 token/s*|✅<br>Mem:5.6G/16G<br>*22.96 token/s*|✅<br>Mem:9.2G/16G<br>*7.48 token/s*|✅<br>Mem:14.8G/16G<br>*3.19 token/s*|
|Xavier NX(8G)<br>Jetpack 5.1|❌|❌|✅<br>Mem:4.35G/8G<br>*28.36 token/s*|❌|❌|


从结果看:
* 20B模型虽然能运行，但是响应速度还是不太理想的，而且几乎把16G的运存给吃满了(可能有的小伙伴对Jetson平台不太熟悉，一种不太严谨的说法，Jetson的内存既是内存，也可以是显存)，也干不了别的事情。
* 综合来看7B的模型在推理速度和性能上是最平衡的，响应速度可以接受(见[视频](https://www.bilibili.com/video/BV1iC411x76Q/))，还留了将近一半显存，可以部署个CV模型之类的做其他事情。
* 代际差距还是很明显的……

大模型能跑在Jetson上，这下可就有很多花活可以整了！智能机器人可以脱离互联网，大模型直接运行于本地，成为真正意义上的“具身”智能。更有意义的是，本与具身智能无缘的自主水下机器人(AUV)也有望搭载大模型，衍生出水下智能集群等一系列颇具前景的工作。

**或者说，离线具身智能纪元已至！**

全链路部署教程已发布在github，踩坑不易，佬如果觉得有用不妨给个star~

[[GitHub]](https://github.com/BestAnHongjun/LMDeploy-Jetson)